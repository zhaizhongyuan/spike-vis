{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "import argparse\n",
    "import time\n",
    "import timm.optim.optim_factory as optim_factory\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import copy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# from config import Config_MBM_SPIKE\n",
    "from config import Config_MBM_fMRI\n",
    "from dataset import allen_dataset_1d, allen_dataset_2d, allen_dataset_static_grating_1d\n",
    "# from sc_mbm.mae_for_spike_train import MAEforSPIKE, spike_encoder\n",
    "from sc_mbm.mae_for_fmri import MAEforFMRI, fmri_encoder, fmri_classifier\n",
    "# from sc_mbm.trainer import train_one_epoch_spike\n",
    "from sc_mbm.trainer import train_one_epoch\n",
    "from sc_mbm.trainer import NativeScalerWithGradNormCount as NativeScaler\n",
    "from sc_mbm.utils import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_START_METHOD\"] = \"thread\"\n",
    "os.environ['WANDB_DIR'] = \".\"\n",
    "\n",
    "class wandb_logger:\n",
    "    def __init__(self, config):\n",
    "        wandb.init(\n",
    "                    project=\"mind-vis\",\n",
    "                    anonymous=\"allow\",\n",
    "                    group='stageA_sc-mbm',\n",
    "                    config=config,\n",
    "                    reinit=True)\n",
    "\n",
    "        self.config = config\n",
    "        self.step = None\n",
    "    \n",
    "    def log(self, name, data, step=None):\n",
    "        if step is None:\n",
    "            wandb.log({name: data})\n",
    "        else:\n",
    "            wandb.log({name: data}, step=step)\n",
    "            self.step = step\n",
    "    \n",
    "    def watch_model(self, *args, **kwargs):\n",
    "        wandb.watch(*args, **kwargs)\n",
    "\n",
    "    def log_image(self, name, fig):\n",
    "        if self.step is None:\n",
    "            wandb.log({name: wandb.Image(fig)})\n",
    "        else:\n",
    "            wandb.log({name: wandb.Image(fig)}, step=self.step)\n",
    "\n",
    "    def finish(self):\n",
    "        wandb.finish(quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_readme(config, path):\n",
    "    print(config.__dict__)\n",
    "    with open(os.path.join(path, 'README.md'), 'w+') as f:\n",
    "        print(config.__dict__, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_readme(config, path):\n",
    "    print(config.__dict__)\n",
    "    with open(os.path.join(path, 'README.md'), 'w+') as f:\n",
    "        print(config.__dict__, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmri_transform(x, sparse_rate=0.2):\n",
    "    # x: 1, num_voxels\n",
    "    x_aug = copy.deepcopy(x)\n",
    "    idx = np.random.choice(x.shape[0], int(x.shape[0]*sparse_rate), replace=False)\n",
    "    x_aug[idx] = 0\n",
    "    return torch.FloatTensor(x_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/1032511/ipykernel_430033/3717549414.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  config = torch.load('../results/spike_pretrain/09-12-2024-00-07-46/checkpoints/checkpoint.pth')['config']\n"
     ]
    }
   ],
   "source": [
    "config = torch.load('../results/spike_pretrain/09-12-2024-00-07-46/checkpoints/checkpoint.pth')['config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzhaizhongyuan\u001b[0m (\u001b[33m11785-bhiksha\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20241209_095608-owzgz0t7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/11785-bhiksha/mind-vis/runs/owzgz0t7' target=\"_blank\">misty-glade-154</a></strong> to <a href='https://wandb.ai/11785-bhiksha/mind-vis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/11785-bhiksha/mind-vis' target=\"_blank\">https://wandb.ai/11785-bhiksha/mind-vis</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/11785-bhiksha/mind-vis/runs/owzgz0t7' target=\"_blank\">https://wandb.ai/11785-bhiksha/mind-vis/runs/owzgz0t7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.00025, 'min_lr': 0.0, 'weight_decay': 0.05, 'num_epoch': 500, 'warmup_epochs': 40, 'batch_size': 32, 'clip_grad': 0.8, 'mask_ratio': 0.75, 'patch_size': 8, 'embed_dim': 128, 'decoder_embed_dim': 512, 'depth': 24, 'num_heads': 16, 'decoder_num_heads': 16, 'mlp_ratio': 1.0, 'root_path': '../', 'output_path': '../results/spike_pretrain/09-12-2024-09-56-08', 'seed': 2022, 'roi': 'VC', 'aug_times': 1, 'num_sub_limit': None, 'include_hcp': True, 'include_kam': True, 'accum_iter': 1, 'use_nature_img_loss': False, 'img_recon_weight': 0.5, 'focus_range': None, 'focus_rate': 0.6, 'local_rank': 0}\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    torch.cuda.set_device(config.local_rank) \n",
    "    torch.distributed.init_process_group(backend='nccl')\n",
    "output_path = os.path.join(config.root_path, 'results', 'spike_pretrain',  '%s'%(datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")))\n",
    "# output_path = os.path.join(config.root_path, 'results', 'fmri_pretrain')\n",
    "config.output_path = output_path\n",
    "logger = wandb_logger(config) if config.local_rank == 0 else None\n",
    "\n",
    "if config.local_rank == 0:\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    create_readme(config, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(f'cuda:{config.local_rank}') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.manual_seed(config.seed)\n",
    "np.random.seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 4800\n",
      "Number of neurons: 1952\n"
     ]
    }
   ],
   "source": [
    "# create dataset and dataloader\n",
    "# allen_dataset = allen_dataset_1d(fmri_transform=fmri_transform)\n",
    "allen_dataset = allen_dataset_static_grating_1d(fmri_transform=fmri_transform)\n",
    "\n",
    "print(f'Dataset size: {len(allen_dataset)}\\nNumber of neurons: {allen_dataset.n_neurons}')\n",
    "sampler = torch.utils.data.DistributedSampler(allen_dataset, rank=config.local_rank) if torch.cuda.device_count() > 1 else None \n",
    "\n",
    "dataloader_allen = DataLoader(allen_dataset, batch_size=config.batch_size, sampler=sampler, \n",
    "            shuffle=(sampler is None), pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 1\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00025\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/ice1/1/7/zzhai37/nsp/mind-vis/code/sc_mbm/trainer.py:13: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self._scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "# config.num_voxels = allen_dataset.n_neurons\n",
    "# model = MAEforSPIKE(img_size=allen_dataset.n_neurons, patch_size=config.patch_size, embed_dim=config.embed_dim,\n",
    "#                 decoder_embed_dim=config.decoder_embed_dim, depth=config.depth, \n",
    "#                 num_heads=config.num_heads, decoder_num_heads=config.decoder_num_heads, mlp_ratio=config.mlp_ratio,\n",
    "#                 focus_range=config.focus_range, focus_rate=config.focus_rate, \n",
    "#                 img_recon_weight=config.img_recon_weight, use_nature_img_loss=config.use_nature_img_loss)\n",
    "model = MAEforFMRI(num_voxels=allen_dataset.n_neurons, patch_size=config.patch_size, embed_dim=config.embed_dim,\n",
    "                decoder_embed_dim=config.decoder_embed_dim, depth=config.depth, \n",
    "                num_heads=config.num_heads, decoder_num_heads=config.decoder_num_heads, mlp_ratio=config.mlp_ratio,\n",
    "                focus_range=config.focus_range, focus_rate=config.focus_rate, \n",
    "                img_recon_weight=config.img_recon_weight, use_nature_img_loss=config.use_nature_img_loss)\n",
    "model.to(device)\n",
    "model_without_ddp = model\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "    model = DistributedDataParallel(model, device_ids=[config.local_rank], output_device=config.local_rank, find_unused_parameters=config.use_nature_img_loss)\n",
    "\n",
    "param_groups = optim_factory.add_weight_decay(model, config.weight_decay)\n",
    "optimizer = torch.optim.AdamW(param_groups, lr=config.lr, betas=(0.9, 0.95))\n",
    "print(optimizer)\n",
    "loss_scaler = NativeScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('../results/spike_pretrain/09-12-2024-00-07-46/checkpoints/checkpoint.pth', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict['model'])\n",
    "optimizer.load_state_dict(state_dict['optimizer'])\n",
    "loss_scaler.load_state_dict(state_dict['scaler'])\n",
    "epoch = state_dict['epoch'] + 1 # begins from next epoch\n",
    "config = state_dict['config']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer weights to a encoder-only model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/1032511/ipykernel_430033/1035432935.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mae_state_dict = torch.load('../results/spike_pretrain/09-12-2024-00-07-46/checkpoints/checkpoint.pth')['model']\n"
     ]
    }
   ],
   "source": [
    "# Load the MAEforSPIKE state_dict\n",
    "mae_state_dict = torch.load('../results/spike_pretrain/09-12-2024-00-07-46/checkpoints/checkpoint.pth')['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(mae_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing keys: []\n",
      "unexpected keys: ['mask_token']\n"
     ]
    }
   ],
   "source": [
    "# Define the keys that belong to the encoder\n",
    "encoder_keys = [key for key in mae_state_dict.keys() if not key.startswith('decoder') and not key.startswith('mask_token')]\n",
    "\n",
    "# Create a new state_dict with only encoder weights\n",
    "encoder_state_dict = {key: mae_state_dict[key] for key in encoder_keys}\n",
    "\n",
    "mae_encoder = fmri_encoder(num_voxels=allen_dataset.n_neurons, patch_size=config.patch_size, embed_dim=config.embed_dim,\n",
    "                 depth=config.depth, num_heads=config.num_heads, mlp_ratio=config.mlp_ratio)\n",
    "m, u = mae_encoder.load_state_dict(encoder_state_dict, strict=False)\n",
    "print('missing keys:', u)\n",
    "print('unexpected keys:', m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_encoder.embed_dim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fmri_classifier(base_encoder=mae_encoder, num_classes=6)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_model(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data_dict in dataloader:\n",
    "        inputs = data_dict['fmri']\n",
    "        labels = data_dict['class_label']\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation loop\n",
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data_dict in dataloader:\n",
    "            inputs = data_dict['fmri']\n",
    "            labels = data_dict['class_label']\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:owzgz0t7) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misty-glade-154</strong> at: <a href='https://wandb.ai/11785-bhiksha/mind-vis/runs/owzgz0t7' target=\"_blank\">https://wandb.ai/11785-bhiksha/mind-vis/runs/owzgz0t7</a><br/> View project at: <a href='https://wandb.ai/11785-bhiksha/mind-vis' target=\"_blank\">https://wandb.ai/11785-bhiksha/mind-vis</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241209_095608-owzgz0t7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:owzgz0t7). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20241209_095621-ox9nu5lg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/11785-bhiksha/fmri-classification/runs/ox9nu5lg' target=\"_blank\">fine-tuning-fmri-encoder</a></strong> to <a href='https://wandb.ai/11785-bhiksha/fmri-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/11785-bhiksha/fmri-classification' target=\"_blank\">https://wandb.ai/11785-bhiksha/fmri-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/11785-bhiksha/fmri-classification/runs/ox9nu5lg' target=\"_blank\">https://wandb.ai/11785-bhiksha/fmri-classification/runs/ox9nu5lg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/11785-bhiksha/fmri-classification/runs/ox9nu5lg?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x155448c1ece0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize W&B\n",
    "wandb.init(project=\"fmri-classification\", name=\"fine-tuning-fmri-encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define split sizes\n",
    "train_size = int(0.8 * len(allen_dataset))  # 80% for training\n",
    "test_size = len(allen_dataset) - train_size  # Remaining 20% for testing\n",
    "\n",
    "# Split dataset\n",
    "train_dataset, test_dataset = random_split(allen_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "param_groups = optim_factory.add_weight_decay(model, config.weight_decay)\n",
    "optimizer = torch.optim.AdamW(param_groups, lr=config.lr, betas=(0.9, 0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Train Loss: 0.3075, Train Acc: 0.9505\n",
      "Val Loss: 0.0339, Val Acc: 0.9938\n",
      "Epoch 2/5\n",
      "Train Loss: 0.0585, Train Acc: 0.9836\n",
      "Val Loss: 0.0225, Val Acc: 0.9927\n",
      "Epoch 3/5\n",
      "Train Loss: 0.0510, Train Acc: 0.9836\n",
      "Val Loss: 0.0414, Val Acc: 0.9885\n",
      "Epoch 4/5\n",
      "Train Loss: 0.0367, Train Acc: 0.9893\n",
      "Val Loss: 0.0593, Val Acc: 0.9792\n",
      "Epoch 5/5\n",
      "Train Loss: 0.0648, Train Acc: 0.9818\n",
      "Val Loss: 0.0284, Val Acc: 0.9917\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluation\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_model(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = evaluate_model(model, val_loader, criterion, device)\n",
    "\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_acc_list.append(val_acc)\n",
    "\n",
    "    # Log metrics to W&B\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_accuracy\": val_acc\n",
    "    })\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
