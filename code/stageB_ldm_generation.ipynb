{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "import argparse\n",
    "import datetime\n",
    "import wandb\n",
    "import torchvision.transforms as transforms\n",
    "from einops import rearrange\n",
    "from PIL import Image\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch.distributed as dist\n",
    "from lightning_utilities.core.rank_zero import rank_zero_only\n",
    "\n",
    "if dist.is_initialized():\n",
    "    rank = dist.get_rank()\n",
    "    rank_zero_only.rank = rank == 0\n",
    "else:\n",
    "    rank_zero_only.rank = True\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import copy\n",
    "\n",
    "# own code\n",
    "from config import Config_Generative_Model\n",
    "from dataset import create_Kamitani_dataset, create_BOLD5000_dataset, create_allen_dataset\n",
    "# from dc_ldm.ldm_for_spike import sLDM\n",
    "from dc_ldm.ldm_for_fmri import fLDM\n",
    "from eval_metrics import get_similarity_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['RANK'] = '0'\n",
    "os.environ['LOCAL_RANK'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.5'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.FloatTensor"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_init(config, output_path):\n",
    "    wandb.init( project='mind-vis',\n",
    "                group=\"stageB_dc-ldm\",\n",
    "                anonymous=\"allow\",\n",
    "                config=config,\n",
    "                reinit=True)\n",
    "    create_readme(config, output_path)\n",
    "\n",
    "def wandb_finish():\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_image(img):\n",
    "    if img.shape[-1] != 3:\n",
    "        img = rearrange(img, 'c h w -> h w c')\n",
    "    img = 255. * img\n",
    "    return Image.fromarray(img.astype(np.uint8))\n",
    "\n",
    "def channel_last(img):\n",
    "        if img.shape[-1] == 3:\n",
    "            return img\n",
    "        return rearrange(img, 'c h w -> h w c')\n",
    "\n",
    "def get_eval_metric(samples, avg=True):\n",
    "    metric_list = ['mse', 'pcc', 'ssim', 'psm']\n",
    "    res_list = []\n",
    "    \n",
    "    gt_images = [img[0] for img in samples]\n",
    "    gt_images = rearrange(np.stack(gt_images), 'n c h w -> n h w c')\n",
    "    samples_to_run = np.arange(1, len(samples[0])) if avg else [1]\n",
    "    for m in metric_list:\n",
    "        res_part = []\n",
    "        for s in samples_to_run:\n",
    "            pred_images = [img[s] for img in samples]\n",
    "            pred_images = rearrange(np.stack(pred_images), 'n c h w -> n h w c')\n",
    "            res = get_similarity_metric(pred_images, gt_images, method='pair-wise', metric_name=m)\n",
    "            res_part.append(np.mean(res))\n",
    "        res_list.append(np.mean(res_part))     \n",
    "    res_part = []\n",
    "    for s in samples_to_run:\n",
    "        pred_images = [img[s] for img in samples]\n",
    "        pred_images = rearrange(np.stack(pred_images), 'n c h w -> n h w c')\n",
    "        res = get_similarity_metric(pred_images, gt_images, 'class', None, \n",
    "                        n_way=50, num_trials=50, top_k=1, device='cuda')\n",
    "        res_part.append(np.mean(res))\n",
    "    res_list.append(np.mean(res_part))\n",
    "    res_list.append(np.max(res_part))\n",
    "    metric_list.append('top-1-class')\n",
    "    metric_list.append('top-1-class (max)')\n",
    "    return res_list, metric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(generative_model, fmri_latents_dataset_train, fmri_latents_dataset_test, config):\n",
    "    grid, _ = generative_model.generate(fmri_latents_dataset_train, config.num_samples, \n",
    "                config.ddim_steps, config.HW, 10) # generate 10 instances\n",
    "    grid_imgs = Image.fromarray(grid.astype(np.uint8))\n",
    "    grid_imgs.save(os.path.join(config.output_path, 'samples_train.png'))\n",
    "    wandb.log({'summary/samples_train': wandb.Image(grid_imgs)})\n",
    "\n",
    "    grid, samples = generative_model.generate(fmri_latents_dataset_test, config.num_samples, \n",
    "                config.ddim_steps, config.HW)\n",
    "    grid_imgs = Image.fromarray(grid.astype(np.uint8))\n",
    "    grid_imgs.save(os.path.join(config.output_path,f'./samples_test.png'))\n",
    "    for sp_idx, imgs in enumerate(samples):\n",
    "        for copy_idx, img in enumerate(imgs[1:]):\n",
    "            img = rearrange(img, 'c h w -> h w c')\n",
    "            Image.fromarray(img).save(os.path.join(config.output_path, \n",
    "                            f'./test{sp_idx}-{copy_idx}.png'))\n",
    "\n",
    "    wandb.log({f'summary/samples_test': wandb.Image(grid_imgs)})\n",
    "\n",
    "    # metric, metric_list = get_eval_metric(samples, avg=config.eval_avg)\n",
    "    # metric_dict = {f'summary/pair-wise_{k}':v for k, v in zip(metric_list[:-2], metric[:-2])}\n",
    "    # metric_dict[f'summary/{metric_list[-2]}'] = metric[-2]\n",
    "    # metric_dict[f'summary/{metric_list[-1]}'] = metric[-1]\n",
    "    # wandb.log(metric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    if img.shape[-1] == 3:\n",
    "        img = rearrange(img, 'h w c -> c h w')\n",
    "    img = torch.tensor(img)\n",
    "    img = img * 2.0 - 1.0 # to -1 ~ 1\n",
    "    return img\n",
    "\n",
    "class random_crop:\n",
    "    def __init__(self, size, p):\n",
    "        self.size = size\n",
    "        self.p = p\n",
    "    def __call__(self, img):\n",
    "        if torch.rand(1) < self.p:\n",
    "            return transforms.RandomCrop(size=(self.size, self.size))(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmri_transform(x, sparse_rate=0.2):\n",
    "    # x: 1, num_voxels\n",
    "    x_aug = copy.deepcopy(x)\n",
    "    idx = np.random.choice(x.shape[0], int(x.shape[0]*sparse_rate), replace=False)\n",
    "    x_aug[idx] = 0\n",
    "    return torch.FloatTensor(x_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_config(args, config):\n",
    "    for attr in config.__dict__:\n",
    "        if hasattr(args, attr):\n",
    "            if getattr(args, attr) != None:\n",
    "                setattr(config, attr, getattr(args, attr))\n",
    "    return config\n",
    "\n",
    "def create_readme(config, path):\n",
    "    print(config.__dict__)\n",
    "    with open(os.path.join(path, 'README.md'), 'w+') as f:\n",
    "        print(config.__dict__, file=f)\n",
    "\n",
    "\n",
    "def create_trainer(num_epoch, precision=32, accumulate_grad_batches=2,logger=None, check_val_every_n_epoch=0):\n",
    "    acc = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "    return pl.Trainer(accelerator=acc, max_epochs=num_epoch, logger=logger, \n",
    "            precision=precision, accumulate_grad_batches=accumulate_grad_batches,\n",
    "            enable_checkpointing=False, enable_model_summary=False, gradient_clip_val=0.5,\n",
    "            check_val_every_n_epoch=check_val_every_n_epoch, devices=1, strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config_Generative_Model()\n",
    "\n",
    "if config.checkpoint_path is not None:\n",
    "    model_meta = torch.load(config.checkpoint_path, map_location='cpu')\n",
    "    ckp = config.checkpoint_path\n",
    "    config = model_meta['config']\n",
    "    config.checkpoint_path = ckp\n",
    "    print('Resuming from checkpoint: {}'.format(config.checkpoint_path))\n",
    "\n",
    "output_path = os.path.join(config.root_path, 'results', 'generation',  '%s'%(datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")))\n",
    "config.output_path = output_path\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mind-vis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
