{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "import argparse\n",
    "import time\n",
    "import timm.optim.optim_factory as optim_factory\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import copy\n",
    "\n",
    "# own code\n",
    "from config import Config_MBM_finetune\n",
    "from dataset import create_Kamitani_dataset, create_BOLD5000_dataset\n",
    "from sc_mbm.mae_for_fmri import MAEforFMRI\n",
    "from sc_mbm.trainer import train_one_epoch\n",
    "from sc_mbm.trainer import NativeScalerWithGradNormCount as NativeScaler\n",
    "from sc_mbm.utils import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wandb_logger:\n",
    "    def __init__(self, config):\n",
    "        wandb.init( project='mind-vis',\n",
    "                    group=\"stepA_sc-mbm_tune\",\n",
    "                    anonymous=\"allow\",\n",
    "                    config=config,\n",
    "                    reinit=True)\n",
    "\n",
    "        self.config = config\n",
    "        self.step = None\n",
    "    \n",
    "    def log(self, name, data, step=None):\n",
    "        if step is None:\n",
    "            wandb.log({name: data})\n",
    "        else:\n",
    "            wandb.log({name: data}, step=step)\n",
    "            self.step = step\n",
    "    \n",
    "    def watch_model(self, *args, **kwargs):\n",
    "        wandb.watch(*args, **kwargs)\n",
    "\n",
    "    def log_image(self, name, fig):\n",
    "        if self.step is None:\n",
    "            wandb.log({name: wandb.Image(fig)})\n",
    "        else:\n",
    "            wandb.log({name: wandb.Image(fig)}, step=self.step)\n",
    "\n",
    "    def finish(self):\n",
    "        wandb.finish(quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser('MAE finetuning on Test fMRI', add_help=False)\n",
    "\n",
    "    # Training Parameters\n",
    "    parser.add_argument('--lr', type=float)\n",
    "    parser.add_argument('--weight_decay', type=float)\n",
    "    parser.add_argument('--num_epoch', type=int)\n",
    "    parser.add_argument('--batch_size', type=int)\n",
    "    parser.add_argument('--mask_ratio', type=float)\n",
    "\n",
    "    # Project setting\n",
    "    parser.add_argument('--root_path', type=str)\n",
    "    parser.add_argument('--pretrain_mbm_path', type=str)\n",
    "    parser.add_argument('--dataset', type=str)\n",
    "    parser.add_argument('--include_nonavg_test', type=bool)   \n",
    "    \n",
    "    # distributed training parameters\n",
    "    parser.add_argument('--local_rank', type=int)\n",
    "                        \n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_readme(config, path):\n",
    "    print(config.__dict__)\n",
    "    with open(os.path.join(path, 'README.md'), 'w+') as f:\n",
    "        print(config.__dict__, file=f)\n",
    "\n",
    "def fmri_transform(x, sparse_rate=0.2):\n",
    "    # x: 1, num_voxels\n",
    "    x_aug = copy.deepcopy(x)\n",
    "    idx = np.random.choice(x.shape[0], int(x.shape[0]*sparse_rate), replace=False)\n",
    "    x_aug[idx] = 0\n",
    "    return torch.FloatTensor(x_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config_MBM_finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzhaizhongyuan\u001b[0m (\u001b[33m11785-bhiksha\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/storage/ice1/1/7/zzhai37/nsp/mind-vis/code/wandb/run-20241122_184644-ti6rqnsv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/11785-bhiksha/mind-vis/runs/ti6rqnsv' target=\"_blank\">cosmic-glade-7</a></strong> to <a href='https://wandb.ai/11785-bhiksha/mind-vis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/11785-bhiksha/mind-vis' target=\"_blank\">https://wandb.ai/11785-bhiksha/mind-vis</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/11785-bhiksha/mind-vis/runs/ti6rqnsv' target=\"_blank\">https://wandb.ai/11785-bhiksha/mind-vis/runs/ti6rqnsv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'root_path': '.', 'output_path': './results/fmri_pretrain/22-11-2024-18-46-43', 'kam_path': './data/Kamitani/npz', 'bold5000_path': './data/BOLD5000', 'dataset': 'GOD', 'pretrain_mbm_path': './pretrains/GOD/fmri_encoder.pth', 'include_nonavg_test': True, 'kam_subs': ['sbj_3'], 'bold5000_subs': ['CSI1'], 'lr': 5.3e-05, 'weight_decay': 0.05, 'num_epoch': 15, 'batch_size': 16, 'mask_ratio': 0.75, 'accum_iter': 1, 'clip_grad': 0.8, 'warmup_epochs': 2, 'min_lr': 0.0, 'local_rank': 0}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Config_MBM_finetune' object has no attribute 'seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     create_readme(config, output_path)\n\u001b[1;32m     13\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcuda:\u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39mlocal_rank\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m) \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m torch\u001b[39m.\u001b[39mmanual_seed(config\u001b[39m.\u001b[39;49mseed)\n\u001b[1;32m     15\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(config\u001b[39m.\u001b[39mseed)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Config_MBM_finetune' object has no attribute 'seed'"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    torch.cuda.set_device(config.local_rank) \n",
    "    torch.distributed.init_process_group(backend='nccl')\n",
    "output_path = os.path.join(config.root_path, 'results', 'fmri_pretrain',  '%s'%(datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")))\n",
    "# output_path = os.path.join(config.root_path, 'results', 'fmri_pretrain')\n",
    "config.output_path = output_path\n",
    "logger = wandb_logger(config) if config.local_rank == 0 else None\n",
    "\n",
    "if config.local_rank == 0:\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    create_readme(config, output_path)\n",
    "\n",
    "device = torch.device(f'cuda:{config.local_rank}') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.manual_seed(config.seed)\n",
    "np.random.seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        torch.cuda.set_device(config.local_rank) \n",
    "        torch.distributed.init_process_group(backend='nccl')\n",
    "    sd = torch.load(config.pretrain_mbm_path, map_location='cpu')\n",
    "    config_pretrain = sd['config']\n",
    "    \n",
    "    output_path = os.path.join(config.root_path, 'results', 'fmri_finetune',  '%s'%(datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")))\n",
    "    # output_path = os.path.join(config.root_path, 'results', 'fmri_finetune')\n",
    "    config.output_path = output_path\n",
    "    logger = wandb_logger(config) if config.local_rank == 0 else None\n",
    "    \n",
    "    if config.local_rank == 0:\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        create_readme(config, output_path)\n",
    "    \n",
    "    device = torch.device(f'cuda:{config.local_rank}') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    torch.manual_seed(config_pretrain.seed)\n",
    "    np.random.seed(config_pretrain.seed)\n",
    "\n",
    "    # create model\n",
    "    num_voxels = (sd['model']['pos_embed'].shape[1] - 1)* config_pretrain.patch_size\n",
    "    model = MAEforFMRI(num_voxels=num_voxels, patch_size=config_pretrain.patch_size, embed_dim=config_pretrain.embed_dim,\n",
    "                    decoder_embed_dim=config_pretrain.decoder_embed_dim, depth=config_pretrain.depth, \n",
    "                    num_heads=config_pretrain.num_heads, decoder_num_heads=config_pretrain.decoder_num_heads, \n",
    "                    mlp_ratio=config_pretrain.mlp_ratio, focus_range=None, use_nature_img_loss=False) \n",
    "    model.load_state_dict(sd['model'], strict=False)\n",
    "\n",
    "    model.to(device)\n",
    "    model_without_ddp = model\n",
    "\n",
    "    # create dataset and dataloader\n",
    "    if config.dataset == 'GOD':\n",
    "        _, test_set = create_Kamitani_dataset(path=config.kam_path, patch_size=config_pretrain.patch_size, \n",
    "                                subjects=config.kam_subs, fmri_transform=torch.FloatTensor, include_nonavg_test=config.include_nonavg_test)\n",
    "    elif config.dataset == 'BOLD5000':\n",
    "        _, test_set = create_BOLD5000_dataset(path=config.bold5000_path, patch_size=config_pretrain.patch_size, \n",
    "                fmri_transform=torch.FloatTensor, subjects=config.bold5000_subs, include_nonavg_test=config.include_nonavg_test)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    print(test_set.fmri.shape)\n",
    "    if test_set.fmri.shape[-1] < num_voxels:\n",
    "        test_set.fmri = np.pad(test_set.fmri, ((0,0), (0, num_voxels - test_set.fmri.shape[-1])), 'wrap')\n",
    "    else:\n",
    "        test_set.fmri = test_set.fmri[:, :num_voxels]\n",
    "    print(f'Dataset size: {len(test_set)}')\n",
    "    sampler = torch.utils.data.DistributedSampler(test_set) if torch.cuda.device_count() > 1 else torch.utils.data.RandomSampler(test_set) \n",
    "    dataloader_hcp = DataLoader(test_set, batch_size=config.batch_size, sampler=sampler)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "        model = DistributedDataParallel(model, device_ids=[config.local_rank], output_device=config.local_rank, find_unused_parameters=config.use_nature_img_loss)\n",
    "\n",
    "    param_groups = optim_factory.add_weight_decay(model, config.weight_decay)\n",
    "    optimizer = torch.optim.AdamW(param_groups, lr=config.lr, betas=(0.9, 0.95))\n",
    "    print(optimizer)\n",
    "    loss_scaler = NativeScaler()\n",
    "\n",
    "    if logger is not None:\n",
    "        logger.watch_model(model,log='all', log_freq=1000)\n",
    "\n",
    "    cor_list = []\n",
    "    start_time = time.time()\n",
    "    print('Finetuning MAE on test fMRI ... ...')\n",
    "    for ep in range(config.num_epoch):\n",
    "        if torch.cuda.device_count() > 1: \n",
    "            sampler.set_epoch(ep) # to shuffle the data at every epoch\n",
    "        cor = train_one_epoch(model, dataloader_hcp, optimizer, device, ep, loss_scaler, logger, config, start_time, model_without_ddp)\n",
    "        cor_list.append(cor)\n",
    "        if (ep % 2 == 0 or ep + 1 == config.num_epoch) and ep != 0 and config.local_rank == 0:\n",
    "            # save models\n",
    "            save_model(config_pretrain, ep, model_without_ddp, optimizer, loss_scaler, os.path.join(output_path,'checkpoints'))\n",
    "            # plot figures\n",
    "            plot_recon_figures(model, device, test_set, output_path, 5, config, logger, model_without_ddp)\n",
    "            \n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print('Training time {}'.format(total_time_str))\n",
    "    if logger is not None:\n",
    "        logger.log('max cor', np.max(cor_list), step=config.num_epoch-1)\n",
    "        logger.finish()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def plot_recon_figures(model, device, dataset, output_path, num_figures = 5, config=None, logger=None, model_without_ddp=None):\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    model.eval()\n",
    "    fig, axs = plt.subplots(num_figures, 3, figsize=(30,15))\n",
    "    fig.tight_layout()\n",
    "    axs[0,0].set_title('Ground-truth')\n",
    "    axs[0,1].set_title('Masked Ground-truth')\n",
    "    axs[0,2].set_title('Reconstruction')\n",
    "\n",
    "    for ax in axs:\n",
    "        sample = next(iter(dataloader))['fmri']\n",
    "        sample = sample.to(device)\n",
    "        _, pred, mask = model(sample, mask_ratio=config.mask_ratio)\n",
    "        sample_with_mask = model_without_ddp.patchify(sample).to('cpu').numpy().reshape(-1, model_without_ddp.patch_size)\n",
    "        pred = model_without_ddp.unpatchify(pred).to('cpu').numpy().reshape(-1)\n",
    "        sample = sample.to('cpu').numpy().reshape(-1)\n",
    "        mask = mask.to('cpu').numpy().reshape(-1)\n",
    "        # cal the cor\n",
    "        cor = np.corrcoef([pred, sample])[0,1]\n",
    "\n",
    "        x_axis = np.arange(0, sample.shape[-1])\n",
    "        # groundtruth\n",
    "        ax[0].plot(x_axis, sample)\n",
    "        # groundtruth with mask\n",
    "        s = 0\n",
    "        for x, m in zip(sample_with_mask,mask):\n",
    "            if m == 0:\n",
    "                ax[1].plot(x_axis[s:s+len(x)], x, color='#1f77b4')\n",
    "            s += len(x)\n",
    "        # pred\n",
    "        ax[2].plot(x_axis, pred)\n",
    "        ax[2].set_ylabel('cor: %.4f'%cor, weight = 'bold')\n",
    "        ax[2].yaxis.set_label_position(\"right\")\n",
    "\n",
    "    fig_name = 'reconst-%s'%(datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\"))\n",
    "    fig.savefig(os.path.join(output_path, f'{fig_name}.png'))\n",
    "    if logger is not None:\n",
    "        logger.log_image('reconst', fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "def update_config(args, config):\n",
    "    for attr in config.__dict__:\n",
    "        if hasattr(args, attr):\n",
    "            if getattr(args, attr) != None:\n",
    "                setattr(config, attr, getattr(args, attr))\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    args = get_args_parser()\n",
    "    args = args.parse_args()\n",
    "    config = Config_MBM_finetune()\n",
    "    config = update_config(args, config)\n",
    "    main(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
